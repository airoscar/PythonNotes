{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sparkhpc.sparkjob:Submitted batch job 630576\n",
      "\n",
      "INFO:sparkhpc.sparkjob:Submitted cluster 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import atexit\n",
    "import sys\n",
    "\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import findspark\n",
    "from sparkhpc import sparkjob\n",
    "\n",
    "#Exit handler to clean up the Spark cluster if the script exits or crashes\n",
    "def exitHandler(sj,sc):\n",
    "    try:\n",
    "        print('Trapped Exit cleaning up Spark Context')\n",
    "        sc.stop()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        print('Trapped Exit cleaning up Spark Job')\n",
    "        sj.stop()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "#Parameters for the Spark cluster\n",
    "nodes=2\n",
    "tasks_per_node=3 \n",
    "memory_per_task=1024 #1 gig per process, adjust accordingly\n",
    "# Please estimate walltime carefully to keep unused Spark clusters from sitting \n",
    "# idle so that others may use the resources.\n",
    "walltime=\"1:00\" #1 hour\n",
    "os.environ['SBATCH_PARTITION']='single' #Set the appropriate ARC partition\n",
    "\n",
    "sj = sparkjob.sparkjob(\n",
    "     ncores=nodes*tasks_per_node,\n",
    "     cores_per_executor=tasks_per_node,\n",
    "     memory_per_core=memory_per_task,\n",
    "     walltime=walltime\n",
    "    )\n",
    "\n",
    "sj.wait_to_start()\n",
    "sc = sj.start_spark()\n",
    "\n",
    "#Register the exit handler                                                                                                     \n",
    "atexit.register(exitHandler,sj,sc)\n",
    "\n",
    "#You need this line if you want to use SparkSQL\n",
    "sqlCtx=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['39, State-gov,77516, Bachelors,13, Never-married, Adm-clerical, Not-in-family, White, Male,2174,0,40, United-States']\n"
     ]
    }
   ],
   "source": [
    "myInfo=sc.textFile(\"./adult.data.csv\")\n",
    "header=myInfo.first()\n",
    "datawithoutHeader=myInfo.filter(lambda x: x != header)\n",
    "\n",
    "print(datawithoutHeader.take(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|      nativecountry|\n",
      "+-------------------+\n",
      "| Dominican-Republic|\n",
      "|            Ireland|\n",
      "|               Cuba|\n",
      "|          Guatemala|\n",
      "|               Iran|\n",
      "|             Taiwan|\n",
      "|        El-Salvador|\n",
      "|      United-States|\n",
      "|              South|\n",
      "|              Japan|\n",
      "+-------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('aggs').getOrCreate()\n",
    "df = spark.read.csv('./adult.data.csv',inferSchema=True,header=True)\n",
    "df.createOrReplaceTempView(\"adultsTbl\")\n",
    "\n",
    "xx=df.sort(df[\"hoursperweek\"].desc()).select(df[\"nativecountry\"]).distinct().limit(10)\n",
    "\n",
    "print(xx.show())\n",
    "#df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' Male', 42.42808627810923], [' Female', 36.410361154953115]]\n"
     ]
    }
   ],
   "source": [
    "myInfo=sc.textFile(\"./adult.data.csv\")\n",
    "header=myInfo.first()\n",
    "datawithoutHeader=myInfo.filter(lambda x: x != header)\n",
    "\n",
    "data = datawithoutHeader.map(lambda x: x.split(\",\"))\n",
    "aggregatedData=data.map(lambda x: (x[9], [int(x[12]),1])).reduceByKey(lambda x,y:[x[0]+y[0],x[1]+y[1]]).map(lambda x:[x[0],x[1][0]/x[1][1]])\n",
    "print(aggregatedData.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using RDD Operation\n",
    "myInfo=sc.textFile(\"./adult.data.csv\")\n",
    "header=myInfo.first()\n",
    "datawithoutHeader=myInfo.filter(lambda x: x != header)\n",
    "ageColumn=datawithoutHeader.map(lambda x:x.split(\",\")[0])\n",
    "#print(ageColumn.collect())\n",
    "\n",
    "#Using Dataframe API\n",
    "\n",
    "#print(df.select(\"age\").show())\n",
    "\n",
    "#Using SQL \n",
    "\n",
    "df.createOrReplaceTempView()\n",
    "\n",
    "#sqlAge=sqlCtx.sql(\"select * from adultsTbl where age < 50\")\n",
    "\n",
    "#print(sqlAge.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+------+-------------+------------+-------------------+------------------+---------------+-------------------+-------+-----------+-----------+------------+--------------+\n",
      "|age|        workclass|fnlwgt|    education|educationnum|      maritalstatus|        occupation|   relationship|               race|    sex|capitalgain|capitalloss|hoursperweek| nativecountry|\n",
      "+---+-----------------+------+-------------+------------+-------------------+------------------+---------------+-------------------+-------+-----------+-----------+------------+--------------+\n",
      "| 53|          Private|234721|         11th|           7| Married-civ-spouse| Handlers-cleaners|        Husband|              Black|   Male|          0|          0|          40| United-States|\n",
      "| 52| Self-emp-not-inc|209642|      HS-grad|           9| Married-civ-spouse|   Exec-managerial|        Husband|              White|   Male|          0|          0|          45| United-States|\n",
      "| 54|          Private|302146|      HS-grad|           9|          Separated|     Other-service|      Unmarried|              Black| Female|          0|          0|          20| United-States|\n",
      "| 59|          Private|109015|      HS-grad|           9|           Divorced|      Tech-support|      Unmarried|              White| Female|          0|          0|          40| United-States|\n",
      "| 56|        Local-gov|216851|    Bachelors|          13| Married-civ-spouse|      Tech-support|        Husband|              White|   Male|          0|          0|          40| United-States|\n",
      "| 54|             null|180211| Some-college|          10| Married-civ-spouse|              null|        Husband| Asian-Pac-Islander|   Male|          0|          0|          60|         South|\n",
      "| 53| Self-emp-not-inc| 88506|    Bachelors|          13| Married-civ-spouse|    Prof-specialty|        Husband|              White|   Male|          0|          0|          40| United-States|\n",
      "| 57|      Federal-gov|337895|    Bachelors|          13| Married-civ-spouse|    Prof-specialty|        Husband|              Black|   Male|          0|          0|          40| United-States|\n",
      "| 53|          Private|144361|      HS-grad|           9| Married-civ-spouse| Machine-op-inspct|        Husband|              White|   Male|          0|          0|          38| United-States|\n",
      "| 53|          Private|169846|      HS-grad|           9| Married-civ-spouse|      Adm-clerical|           Wife|              White| Female|          0|          0|          40| United-States|\n",
      "| 79|          Private|124744| Some-college|          10| Married-civ-spouse|    Prof-specialty| Other-relative|              White|   Male|          0|          0|          20| United-States|\n",
      "| 67|             null|212759|         10th|           6| Married-civ-spouse|              null|        Husband|              White|   Male|          0|          0|           2| United-States|\n",
      "| 52|          Private|276515|    Bachelors|          13| Married-civ-spouse|     Other-service|        Husband|              White|   Male|          0|          0|          40|          Cuba|\n",
      "| 59|          Private|159937|      HS-grad|           9| Married-civ-spouse|             Sales|        Husband|              White|   Male|          0|          0|          48| United-States|\n",
      "| 53|          Private|346253|      HS-grad|           9|           Divorced|             Sales|      Own-child|              White| Female|          0|          0|          35| United-States|\n",
      "| 57|          Private|249977|    Assoc-voc|          11| Married-civ-spouse|    Prof-specialty|        Husband|              White|   Male|          0|          0|          40| United-States|\n",
      "| 76|          Private|124191|      Masters|          14| Married-civ-spouse|   Exec-managerial|        Husband|              White|   Male|          0|          0|          40| United-States|\n",
      "| 56| Self-emp-not-inc|335605|      HS-grad|           9| Married-civ-spouse|     Other-service|        Husband|              White|   Male|          0|       1887|          50|        Canada|\n",
      "| 53|          Private| 95647|          9th|           5| Married-civ-spouse| Handlers-cleaners|        Husband|              White|   Male|          0|          0|          50| United-States|\n",
      "| 56|     Self-emp-inc|303090| Some-college|          10| Married-civ-spouse|             Sales|        Husband|              White|   Male|          0|          0|          50| United-States|\n",
      "+---+-----------------+------+-------------+------------+-------------------+------------------+---------------+-------------------+-------+-----------+-----------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Using RDD Operation\n",
    "#ageColumn=datawithoutHeader.map(lambda x:x.split(\",\")[0]).filter(lambda x: int(x)>10)\n",
    "#print(ageColumn.collect())\n",
    "\n",
    "#Using Dataframe API\n",
    "\n",
    "#print(df.select(\"age\").where(df.age>10).show())\n",
    "\n",
    "#Using SQL \n",
    "\n",
    "df.createOrReplaceTempView(\"adultsTbl\")\n",
    "\n",
    "sqlAge=sqlCtx.sql(\"select * from adultsTbl where age > 50\")\n",
    "\n",
    "print(sqlAge.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('armed-forces', 3), ('priv-house-serv', 20), ('protective-serv', 389), ('tech-support', 410), ('handlers-cleaners', 490), ('farming-fishing', 600), ('', 668), ('other-service', 786), ('transport-moving', 1014), ('machine-op-inspct', 1017), ('adm-clerical', 1050), ('sales', 1699), ('prof-specialty', 2176), ('exec-managerial', 2476), ('craft-repair', 2619)]\n"
     ]
    }
   ],
   "source": [
    "#RDD Operations\n",
    "myInfo=sc.textFile('./adult.data.csv')\n",
    "header=myInfo.first()\n",
    "datawithoutHeader=myInfo.filter(lambda x: x != header)\n",
    "data = datawithoutHeader.filter(lambda x: x.split(\",\")[5].lstrip().startswith(\"Married-\")).map(lambda w: (w.split(\",\")[6].lower().strip(),1)).reduceByKey(lambda i,j: i+j).sortBy(lambda x:x[1]) #word count\n",
    "\n",
    "\n",
    "print(data.collect())\n",
    "\n",
    "#print(\"hello\")\n",
    "\n",
    "#data = datawithoutHeader.map(lambda x: x.split(\",\")).filter(lambda x: x[5].strip().startswith(\"Married-\")).Flatmap(lambda w: (w[6].strip(),1)).reduceByKey(lambda i,j: i+j) \n",
    "\n",
    "#print(data.collect())\n",
    "\n",
    "\n",
    "#sqlOcc=sqlCtx.sql(\"\"\"SELECT occupation,ROUND(AVG(if(LTRIM(maritalstatus) LIKE 'Married-%',1,0)),2) as marriedrate FROM adultsTbl group by occupation\"\"\")\n",
    "\n",
    "#print(sqlOcc.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+-----------+\n",
      "|        occupation|  xx|marriedrate|\n",
      "+------------------+----+-----------+\n",
      "|      Craft-repair|2619|       0.64|\n",
      "|   Exec-managerial|2476|       0.61|\n",
      "|    Prof-specialty|2176|       0.53|\n",
      "|             Sales|1699|       0.47|\n",
      "|      Adm-clerical|1050|       0.28|\n",
      "| Machine-op-inspct|1017|       0.51|\n",
      "|  Transport-moving|1014|       0.63|\n",
      "|     Other-service| 786|       0.24|\n",
      "|              null| 668|       0.36|\n",
      "|   Farming-fishing| 600|        0.6|\n",
      "| Handlers-cleaners| 490|       0.36|\n",
      "|      Tech-support| 410|       0.44|\n",
      "|   Protective-serv| 389|        0.6|\n",
      "|   Priv-house-serv|  20|       0.13|\n",
      "|      Armed-Forces|   3|       0.33|\n",
      "+------------------+----+-----------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sqlOcc=sqlCtx.sql(\"\"\"SELECT occupation,sum(if(LTRIM(maritalstatus) LIKE 'Married-%',1,0)) as xx,ROUND(AVG(if(LTRIM(maritalstatus) LIKE 'Married-%',1,0)),2) as marriedrate FROM adultsTbl GROUP BY occupation\n",
    "  ORDER BY xx DESC\"\"\")\n",
    "\n",
    "print(sqlOcc.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+\n",
      "|      occupation|divorcedrate|\n",
      "+----------------+------------+\n",
      "|    Adm-clerical|        0.22|\n",
      "| Priv-house-serv|        0.19|\n",
      "|    Tech-support|        0.15|\n",
      "|   Other-service|        0.15|\n",
      "| Exec-managerial|        0.15|\n",
      "+----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import what we will need\n",
    "from pyspark.sql.functions import when, col, mean, desc, round\n",
    "\n",
    "# wrangle the data a bit\n",
    "df_result = df.select(\n",
    "  df['occupation'], \n",
    "  # create a 1/0 type col on the fly\n",
    "  when( col('maritalstatus') == ' Divorced' , 1 ).otherwise(0).alias('isdivorced')\n",
    ")\n",
    "# do grouping (and a round)\n",
    "df_result = df_result.groupBy('occupation').agg(round(mean('isdivorced'),2).alias('divorcedrate'))\n",
    "# do ordering\n",
    "df_result = df_result.orderBy(desc('divorcedrate'))\n",
    "# show results\n",
    "df_result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
