{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "%run utils.ipynb\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-workplace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-heath",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# def get_vectorized_data(text_array, dim_reduction=True):\n",
    "#     tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_df=0.95)\n",
    "#     X = tfidf_vectorizer.fit_transform(text_array) #features\n",
    "#     if dim_reduction:\n",
    "#         return reduce_vector_dimension(X)\n",
    "#     else:\n",
    "#         return X.toarray()\n",
    "    \n",
    "# def reduce_vector_dimension(X):\n",
    "#     lsa = TruncatedSVD(n_components=100, n_iter=10, random_state=3)\n",
    "#     X = lsa.fit_transform(X)\n",
    "#     return X\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df=2, max_df=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-device",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['hypertension'].map({\"Yes\": 1, \"Maybe\": 1, \"No\": 0}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 300, 1000] #number of trees, change it to 1000 for better results\n",
    "max_depth = [3,5,6]\n",
    "learning_rate = [0.05] #so called `eta` value\n",
    "reg_lambda = [0,0.5,1,2] #L2 regularization term on weights\n",
    "reg_alpha = [0,0.5,1,2] #L1 regularization term on weights \n",
    "objective = ['binary:logistic']\n",
    "min_child_weight = [4,8,16]\n",
    "subsample = [0.8]\n",
    "colsample_bytree = [0.7]\n",
    "random_state = [3]\n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    learning_rate=learning_rate,\n",
    "    reg_lambda=reg_lambda,\n",
    "    reg_alpha=reg_alpha,\n",
    "    objective=objective,\n",
    "    min_child_weight=min_child_weight,\n",
    "    subsample=subsample,\n",
    "    colsample_bytree=colsample_bytree,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "gridsearch = GridSearchCV(clf,\n",
    "                          params,\n",
    "                          cv = 5,\n",
    "                          verbose = 1, \n",
    "                          n_jobs = -1,\n",
    "                          scoring = 'roc_auc')\n",
    "\n",
    "xgb_best_model = gridsearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-protest",
   "metadata": {},
   "source": [
    "Best parameters when using full text data (scoring = accuracy)\n",
    "{'colsample_bytree': 0.7,\n",
    " 'learning_rate': 0.05,\n",
    " 'max_depth': 3,\n",
    " 'min_child_weight': 8,\n",
    " 'n_estimators': 300,\n",
    " 'objective': 'binary:logistic',\n",
    " 'random_state': 3,\n",
    " 'reg_alpha': 2,\n",
    " 'reg_lambda': 0,\n",
    " 'subsample': 0.8}\n",
    " score = 0.7994599152272002\n",
    " \n",
    " \n",
    " Best parameters when using partial text data (scoring = roc_auc)\n",
    " {'colsample_bytree': 0.7,\n",
    " 'learning_rate': 0.05,\n",
    " 'max_depth': 3,\n",
    " 'min_child_weight': 4,\n",
    " 'n_estimators': 100,\n",
    " 'objective': 'binary:logistic',\n",
    " 'random_state': 3,\n",
    " 'reg_alpha': 0.5,\n",
    " 'reg_lambda': 0,\n",
    " 'subsample': 0.8}\n",
    " score = 0.8719259788504541\n",
    " \n",
    " Best parameters when using full text data (scoring = roc_auc)\n",
    " {'colsample_bytree': 0.7,\n",
    " 'learning_rate': 0.05,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 8,\n",
    " 'n_estimators': 300,\n",
    " 'objective': 'binary:logistic',\n",
    " 'random_state': 3,\n",
    " 'reg_alpha': 1,\n",
    " 'reg_lambda': 0,\n",
    " 'subsample': 0.8}\n",
    " score = 0.9579638001758906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-merit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "aModel = xgb.XGBClassifier(\n",
    "    colsample_bytree=0.7,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    min_child_weight=8,\n",
    "    n_estimators=300,\n",
    "    objective='binary:logistic',\n",
    "    random_state=3,\n",
    "    reg_alpha=1,\n",
    "    reg_lambda=0,\n",
    "    subsample=0.8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "aModel.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "aModel.save_model(\"xgb_hypertension.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-richmond",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-marketplace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,shuffle=True,random_state=3,stratify = y,)\n",
    "# aModel.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "# y_pred = aModel.predict(X_test)\n",
    "# f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.Booster({'nthread':2})\n",
    "xgb_model.load_model(\"xgb_hypertension.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
